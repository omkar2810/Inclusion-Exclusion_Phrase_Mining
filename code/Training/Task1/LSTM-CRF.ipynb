{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "- BiLSTM\n",
    "- BiLSTM CRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, SimpleRNN, Flatten,\\\n",
    "Activation, RepeatVector, Permute, merge, Lambda\n",
    "from keras_contrib.layers import CRF\n",
    "import keras.optimizers as ko\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import keras\n",
    "import subprocess\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Task1.csv')\n",
    "data = data.rename(columns={'id':'Sentence #'})\n",
    "data = data.drop('Unnamed: 0',axis=1)\n",
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B_EXC</th>\n",
       "      <td>1176</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_INC</th>\n",
       "      <td>1223</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXC</th>\n",
       "      <td>5713</td>\n",
       "      <td>5713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC</th>\n",
       "      <td>5455</td>\n",
       "      <td>5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>29976</td>\n",
       "      <td>29976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #  words\n",
       "labels                   \n",
       "B_EXC         1176   1176\n",
       "B_INC         1223   1223\n",
       "EXC           5713   5713\n",
       "INC           5455   5455\n",
       "O            29976  29976"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('labels').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"words\"].values.tolist(),\n",
    "                                                           s[\"labels\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        \n",
    "words = list(set(data[\"words\"].values))\n",
    "tags = ['O','B_INC','INC','B_EXC','EXC']\n",
    "# tags = list(set(data[\"labels\"].values))\n",
    "n_words = len(words)\n",
    "n_tags = len(tags)\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences\n",
    "\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "max_len = 170\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]    \n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n",
    "y = [np.array([tag2idx[w[1]] for w in s]) for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y = np.array([to_categorical(i, num_classes=n_tags) for i in y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Create embedding weight matrix\n",
    "\n",
    "def loadGloveModel(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(File,'r')\n",
    "    gloveModel = {}\n",
    "    for line in f:\n",
    "        splitLines = line.split()\n",
    "        word = splitLines[0]\n",
    "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "        gloveModel[word] = wordEmbedding\n",
    "    print(len(gloveModel),\" words loaded!\")\n",
    "    return gloveModel\n",
    "\n",
    "vec_model = loadGloveModel('glove/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4916, 200)\n"
     ]
    }
   ],
   "source": [
    "emb_dim = len(vec_model['the'])\n",
    "embedding_matrix = np.zeros((len(word2idx) + 1, emb_dim))\n",
    "\n",
    "for word, i in word2idx.items():\n",
    "    if word not in vec_model:\n",
    "        continue\n",
    "    embedding_vector = vec_model[word]\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_model.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result,file,ign):\n",
    "    idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "    with open(file,'w+') as f:\n",
    "        for i,lis in enumerate(result):\n",
    "            line = \"\"\n",
    "            for el in lis:\n",
    "                tag = idx2tag[el]\n",
    "                if tag in ['O',ign,'B_'+ign]:\n",
    "                    line += \"O \"\n",
    "                elif tag[0] == 'B':\n",
    "                    line += 'B '\n",
    "                else:\n",
    "                    line += 'I '\n",
    "            f.write(line+'\\n')\n",
    "            \n",
    "def get_sampleWeights(class_weights):\n",
    "    sample_weights=np.random.rand(X_train.shape[0], X_train.shape[1])\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            sample_weights[i][j]=class_weights[np.argmax(y_train[i][j])]\n",
    "    return sample_weights\n",
    "\n",
    "def get_softMetrics(pred,labels,ign):\n",
    "\n",
    "    write_results(pred,'pred.txt',ign)\n",
    "    write_results(labels,'labels.txt',ign)\n",
    "    out = subprocess.check_output(['./a.out']).decode('utf-8').split('\\n')\n",
    "    rows = []\n",
    "    for item in  out:\n",
    "        item = item.split(\" \")\n",
    "        if len(item) != 2:continue \n",
    "        rows.append({'Proportional':item[0],'Binary':item[1]})\n",
    "    \n",
    "    return (pd.DataFrame(rows,index=['precision','recall','F1']))\n",
    "\n",
    "def return_report(model,epochs):\n",
    "    y_flat = list(np.argmax(y_test,2).flatten('F'))\n",
    "#     class_weights = class_weight.compute_class_weight('balanced',y_flat)\n",
    "    class_weights = [1,20,20,20,20]\n",
    "    model.fit(X_train,y_train,epochs=epochs,verbose=1)\n",
    "    out = model.predict(X_test)\n",
    "    pred = np.argmax(out,2)\n",
    "    labels = np.argmax(y_test,2)\n",
    "    inc = get_softMetrics(pred,labels,'INC')\n",
    "    exc = get_softMetrics(pred,labels,'EXC')\n",
    "    display(inc)\n",
    "    display(exc)\n",
    "    report = classification_report(np.argmax(y_test,2).flatten('F'),pred.flatten('F'),output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "#     display(df)\n",
    "    return pred\n",
    "#     return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    X = crf.input\n",
    "    mask = crf.input_mask\n",
    "    nloglik = crf.get_negative_log_likelihood(y_true, X, mask)\n",
    "    return keras.activations.relu(nloglik)\n",
    "\n",
    "def lstm_crf():\n",
    "    input = Input(shape=(max_len,))\n",
    "    model = Embedding(input_dim=n_words + 1, output_dim=emb_dim,\n",
    "                      input_length=max_len, weights=[embedding_matrix],trainable=True)(input)  # 20-dim embedding\n",
    "    model = Bidirectional(LSTM(units=emb_dim, return_sequences=True,\n",
    "                               recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "    \n",
    "    model = TimeDistributed(Dense(2*emb_dim, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "    crf = CRF(n_tags,sparse_target=False)  # CRF layer\n",
    "    out = crf(model)  # output\n",
    "\n",
    "    adam = ko.Adam(lr=0.0008)\n",
    "    sgd = ko.SGD(lr=0.05,momentum=0.7)\n",
    "    rmsprop = ko.RMSprop(lr=0.001)\n",
    "    model = Model(input, out)\n",
    "    model.compile(optimizer='rmsprop', loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_bilstm_lstm_model():\n",
    "    \n",
    "    input = Input(shape=(max_len,))\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model = Embedding(input_dim=n_words + 1, output_dim=emb_dim,\n",
    "                  input_length=max_len, weights=[embedding_matrix],trainable=True)(input)\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model = Bidirectional(LSTM(units=emb_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))(model)\n",
    "\n",
    "    # Add LSTM\n",
    "    model = Bidirectional(LSTM(units=emb_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.1))(model)\n",
    "    \n",
    "    # Add timeDistributed Layer\n",
    "    out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)\n",
    "\n",
    "    #Optimiser \n",
    "    adam = ko.Adam(lr=0.0009)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(input, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = get_bilstm_lstm_model()\n",
    "labels = return_report(bilstm,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 170, 300)          1474800   \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 170, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 170, 600)          360600    \n",
      "_________________________________________________________________\n",
      "crf_12 (CRF)                 (None, 170, 5)            3040      \n",
      "=================================================================\n",
      "Total params: 3,280,840\n",
      "Trainable params: 3,280,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "1723/1723 [==============================] - 55s 32ms/step - loss: 0.1762 - crf_viterbi_accuracy: 0.9440\n",
      "Epoch 2/25\n",
      "1723/1723 [==============================] - 53s 31ms/step - loss: 0.1040 - crf_viterbi_accuracy: 0.9672\n",
      "Epoch 3/25\n",
      "1723/1723 [==============================] - 54s 31ms/step - loss: 0.0867 - crf_viterbi_accuracy: 0.9706\n",
      "Epoch 4/25\n",
      "1723/1723 [==============================] - 53s 31ms/step - loss: 0.0744 - crf_viterbi_accuracy: 0.9741\n",
      "Epoch 5/25\n",
      "1723/1723 [==============================] - 55s 32ms/step - loss: 0.0634 - crf_viterbi_accuracy: 0.9769\n",
      "Epoch 6/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0527 - crf_viterbi_accuracy: 0.9805\n",
      "Epoch 7/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0440 - crf_viterbi_accuracy: 0.9835\n",
      "Epoch 8/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0365 - crf_viterbi_accuracy: 0.9864\n",
      "Epoch 9/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0303 - crf_viterbi_accuracy: 0.9890\n",
      "Epoch 10/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0241 - crf_viterbi_accuracy: 0.9913\n",
      "Epoch 11/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0200 - crf_viterbi_accuracy: 0.9929\n",
      "Epoch 12/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0156 - crf_viterbi_accuracy: 0.9948\n",
      "Epoch 13/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0132 - crf_viterbi_accuracy: 0.9957\n",
      "Epoch 14/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0106 - crf_viterbi_accuracy: 0.9968\n",
      "Epoch 15/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0085 - crf_viterbi_accuracy: 0.9975\n",
      "Epoch 16/25\n",
      "1723/1723 [==============================] - 53s 31ms/step - loss: 0.0073 - crf_viterbi_accuracy: 0.9978\n",
      "Epoch 17/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0059 - crf_viterbi_accuracy: 0.9982\n",
      "Epoch 18/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0048 - crf_viterbi_accuracy: 0.9985\n",
      "Epoch 19/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0034 - crf_viterbi_accuracy: 0.9990\n",
      "Epoch 20/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0034 - crf_viterbi_accuracy: 0.9988\n",
      "Epoch 21/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0021 - crf_viterbi_accuracy: 0.9992\n",
      "Epoch 22/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0015 - crf_viterbi_accuracy: 0.9993\n",
      "Epoch 23/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 0.0014 - crf_viterbi_accuracy: 0.9992\n",
      "Epoch 24/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 4.2478e-04 - crf_viterbi_accuracy: 0.9995\n",
      "Epoch 25/25\n",
      "1723/1723 [==============================] - 52s 30ms/step - loss: 1.0765e-04 - crf_viterbi_accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proportional</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.473679</td>\n",
       "      <td>0.60793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.606245</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.531826</td>\n",
       "      <td>0.646579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Proportional    Binary\n",
       "precision     0.473679   0.60793\n",
       "recall        0.606245  0.690476\n",
       "F1            0.531826  0.646579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proportional</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.318234</td>\n",
       "      <td>0.401575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.664627</td>\n",
       "      <td>0.774436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.43039</td>\n",
       "      <td>0.528896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Proportional    Binary\n",
       "precision     0.318234  0.401575\n",
       "recall        0.664627  0.774436\n",
       "F1             0.43039  0.528896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crf = lstm_crf()\n",
    "pred = return_report(crf,25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
