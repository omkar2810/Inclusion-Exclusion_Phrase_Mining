{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collab Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pKSz1h4WTI5s",
    "outputId": "5f5b4706-c96b-49f8-c5a7-6b8f5172893d"
   },
   "outputs": [],
   "source": [
    "# Mount the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "hGkq0mBiTNhd",
    "outputId": "f194bc59-424d-4a92-bbb4-bcb3c3094540"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "PATH = 'drive/My Drive/Seq_Classification/'\n",
    "\n",
    "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc_plugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eteib1lMYTs0"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('drive/My Drive/Seq_Classification/Task1.csv')\n",
    "data = data.rename(columns={'id':'Sentence #'})\n",
    "data = data.drop('Unnamed: 0',axis=1)\n",
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUfc443cYXH6"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"words\"].values.tolist(),\n",
    "                                                           s[\"labels\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        \n",
    "words = list(set(data[\"words\"].values))\n",
    "tags = ['O','B_INC','INC','B_EXC','EXC']\n",
    "# tags = list(set(data[\"labels\"].values))\n",
    "n_words = len(words)\n",
    "n_tags = len(tags)\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences\n",
    "\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "max_len = 170\n",
    "X = [[w[0] for w in s] for s in sentences]    \n",
    "# X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value='_PAD_')\n",
    "new_X = []\n",
    "for seq in X:\n",
    "    new_seq = []\n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            new_seq.append(seq[i])\n",
    "        except:\n",
    "            new_seq.append(\"__PAD__\")\n",
    "    new_X.append(new_seq)\n",
    "X = new_X\n",
    "y = [np.array([tag2idx[w[1]] for w in s]) for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "# y = np.array([to_categorical(i, num_classes=n_tags) for i in y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSoJO1IoYfc5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5RknrC2YfkV"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "wk-zcyvLYfgi",
    "outputId": "a3564de9-6e38-42f7-9a6f-0cb03a2c7302"
   },
   "outputs": [],
   "source": [
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "sess.run(tf.compat.v1.initialize_all_variables())\n",
    "sess.run(tf.compat.v1.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "m9fEPYz8ZmFv",
    "outputId": "794485b2-5c6d-4d0f-c348-014f3e1afae5"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKl8vRfdZlz-"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
    "\n",
    "tags = ['O','B_INC','INC','B_EXC','EXC']\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "\n",
    "def write_results(result,file,ign):\n",
    "    print(\"Writing the results for {} token\".format(ign))\n",
    "    idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "    with open(file,'w+') as f:\n",
    "        for i,lis in enumerate(result):\n",
    "            line = \"\"\n",
    "            for el in lis:\n",
    "                tag = idx2tag[el]\n",
    "                if tag in ['O',ign,'B_'+ign]:\n",
    "                    line += \"O \"\n",
    "                elif tag[0] == 'B':\n",
    "                    line += 'B '\n",
    "                else:\n",
    "                    line += 'I '\n",
    "            f.write(line+'\\n')\n",
    "            \n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\n",
    "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
    "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
    "                      },\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]\n",
    "def lstm_elmo():\n",
    "  input_text = Input(shape=(max_len,), dtype=tf.string)\n",
    "  embedding = Lambda(ElmoEmbedding, output_shape=(None, 1024))(input_text)\n",
    "  x = Bidirectional(LSTM(units=300, return_sequences=True,\n",
    "                        recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "  x_rnn = Bidirectional(LSTM(units=300, return_sequences=True,\n",
    "                            recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "  x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
    "  out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
    "\n",
    "  model = Model(input_text, out)\n",
    "  model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "  model.summary()\n",
    "  return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "d0_UkdcJaZRK",
    "outputId": "3c00ab5d-d99d-4e42-b541-1e6e15dc563e"
   },
   "outputs": [],
   "source": [
    "total = int(len(X_train)/batch_size)\n",
    "train_split = int(total*1)\n",
    "val_split = total - train_split\n",
    "print(train_split)\n",
    "X_tr, X_val = X_train[:train_split*batch_size], X_train[-val_split*batch_size:]\n",
    "y_tr, y_val = y_train[:train_split*batch_size], y_train[-val_split*batch_size:]\n",
    "# y_train = y_train.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
    "\n",
    "lstm = lstm_elmo()\n",
    "lstm.fit(np.array(X_tr),y_tr,epochs=10,verbose=1,batch_size=32)\n",
    "out = lstm.predict(np.array(X_test[0:320]))\n",
    "pred = np.argmax(out,2)\n",
    "labels = y_test[0:320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMXFnYY6aZYT"
   },
   "outputs": [],
   "source": [
    "write_results(pred,PATH+'pred.txt','INC')\n",
    "write_results(labels,PATH+'labels.txt','INC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the results for one token and run the next cell to get the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "p1Hrh4hGYfTp",
    "outputId": "8910e0b1-f751-48e4-fb25-255bef826bac"
   },
   "outputs": [],
   "source": [
    "#@title Calculate Metrics\n",
    "#cpp code\n",
    "%%cu\n",
    "\n",
    "#include<bits/stdc++.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "struct Res\n",
    "{\n",
    "    vector<double> vec[3];  \n",
    "};\n",
    "\n",
    "Res testSequential(vector<vector<string> > &sents, \n",
    "                                         vector<vector<string> > &labels) {\n",
    "  uint nExprPredicted = 0;\n",
    "  double nExprPredictedCorrectly = 0;\n",
    "  uint nExprTrue = 0;\n",
    "  double precNumerProp = 0, precNumerBin = 0;\n",
    "  double recallNumerProp = 0, recallNumerBin = 0;\n",
    "  for (uint i=0; i<sents.size(); i++) { // per sentence\n",
    "    vector<string> labelsPredicted;\n",
    "    // forward(sents[i]);\n",
    "\n",
    "    for (uint j=0; j<sents[i].size(); j++) {\n",
    "        labelsPredicted.push_back(sents[i][j]);\n",
    "    }\n",
    "    // assert(labelsPredicted.size() == y.cols());\n",
    "\n",
    "\n",
    "    string y, t, py=\"\", pt=\"\";\n",
    "    uint match = 0;\n",
    "    uint exprSize = 0;\n",
    "    vector<pair<uint,uint> > pred, tru;\n",
    "    int l1=-1, l2=-1;\n",
    "\n",
    "    if (labels[i].size() != labelsPredicted.size())\n",
    "      cout << labels[i].size() << \" \" << labelsPredicted.size() << endl;\n",
    "    for (uint j=0; j<labels[i].size(); j++) { // per token in a sentence\n",
    "      t = labels[i][j];\n",
    "      y = labelsPredicted[j];\n",
    "\n",
    "      if (t == \"B\") {\n",
    "        //nExprTrue++;\n",
    "        if (l1 != -1)\n",
    "          tru.push_back(make_pair(l1,j));\n",
    "        l1 = j;\n",
    "      } else if (t == \"I\") {\n",
    "        // cout<<\"Sentence: \"<<i<<\" Index: \"<<j<<endl;\n",
    "        ;\n",
    "        // assert(l1 != -1);\n",
    "      } else if (t == \"O\") {\n",
    "        if (l1 != -1)\n",
    "          tru.push_back(make_pair(l1,j));\n",
    "        l1 = -1;\n",
    "      } else{\n",
    "          cout<<t<<endl;\n",
    "        assert(false);\n",
    "      }\n",
    "      if ((y == \"B\") || ((y == \"I\") && ((py == \"\") || (py == \"O\")))) {\n",
    "        nExprPredicted++;\n",
    "        if (l2 != -1)\n",
    "          pred.push_back(make_pair(l2,j));\n",
    "        l2 = j;\n",
    "      } else if (y == \"I\") {\n",
    "        assert(l2 != -1);\n",
    "      } else if (y == \"O\") {\n",
    "        if (l2 != -1)\n",
    "          pred.push_back(make_pair(l2,j));\n",
    "        l2 = -1;\n",
    "      } else { \n",
    "        cout << y << endl;\n",
    "        assert(false);\n",
    "      }\n",
    "\n",
    "      py = y;\n",
    "      pt = t;\n",
    "    }\n",
    "    if ((l1 != -1) && (l1 != labels[i].size()))\n",
    "      tru.push_back(make_pair(l1,labels[i].size()));\n",
    "    if ((l2 != -1) && (l2 != labels[i].size()))\n",
    "      pred.push_back(make_pair(l2,labels[i].size()));\n",
    "\n",
    "    vector<bool> trum = vector<bool>(tru.size(),false);\n",
    "      vector<bool> predm = vector<bool>(pred.size(),false);\n",
    "    for (uint a=0; a<tru.size(); a++) {\n",
    "      pair<uint,uint> truSpan = tru[a];\n",
    "      nExprTrue++;\n",
    "      for (uint b=0; b<pred.size(); b++) {\n",
    "        pair<uint,uint> predSpan = pred[b];\n",
    "\n",
    "        uint lmax, rmin;\n",
    "        if (truSpan.first > predSpan.first)\n",
    "          lmax = truSpan.first;\n",
    "        else\n",
    "          lmax = predSpan.first;\n",
    "        if (truSpan.second < predSpan.second)\n",
    "          rmin = truSpan.second;\n",
    "        else\n",
    "          rmin = predSpan.second;\n",
    "\n",
    "        uint overlap = 0;\n",
    "        if (rmin > lmax)\n",
    "          overlap = rmin-lmax;\n",
    "        if (predSpan.second == predSpan.first) cout << predSpan.first << endl;\n",
    "        assert(predSpan.second != predSpan.first);\n",
    "        precNumerProp += (double)overlap/(predSpan.second-predSpan.first);\n",
    "        recallNumerProp += (double)overlap/(truSpan.second-truSpan.first);\n",
    "        if (!predm[b] && overlap > 0) {\n",
    "          precNumerBin += (double)(overlap>0);\n",
    "          predm[b] = true;\n",
    "        }\n",
    "        if (!trum[a] && overlap>0) {\n",
    "          recallNumerBin += 1;\n",
    "          trum[a]=true;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "  }\n",
    "  double precisionProp = (nExprPredicted==0) ? 1 : precNumerProp/nExprPredicted;\n",
    "  double recallProp = recallNumerProp/nExprTrue;\n",
    "  double f1Prop = (2*precisionProp*recallProp)/(precisionProp+recallProp);\n",
    "  double precisionBin = (nExprPredicted==0) ? 1 : precNumerBin/nExprPredicted;\n",
    "  double recallBin = recallNumerBin/nExprTrue;\n",
    "  double f1Bin = (2*precisionBin*recallBin)/(precisionBin+recallBin);\n",
    "\n",
    "  Res results;\n",
    "  results.vec[0].push_back(precisionProp); results.vec[0].push_back(precisionBin);\n",
    "  results.vec[1].push_back(recallProp); results.vec[1].push_back(recallBin);\n",
    "  results.vec[2].push_back(f1Prop); results.vec[2].push_back(f1Bin);\n",
    "  return results;\n",
    "}\n",
    "\n",
    "\n",
    "int main()\n",
    "{\n",
    "    vector<vector<string> > pred;\n",
    "    vector<vector<string> > labels;\n",
    "\n",
    "    std::ifstream file(\"drive/My Drive/Seq_Classification/pred.txt\");\n",
    "    if (file.is_open()) {\n",
    "        std::string line;\n",
    "        while (std::getline(file, line)) \n",
    "        {\n",
    "            // using printf() in all tests for consistency\n",
    "            vector<string> temp;\n",
    "            for(int i=0;i<line.length();i+=2)\n",
    "            {\n",
    "                string tag(1,line[i]);\n",
    "                temp.push_back(tag);\n",
    "            }\n",
    "            pred.push_back(temp);\n",
    "        }\n",
    "        file.close();\n",
    "    }\n",
    "\n",
    "\n",
    "    std::ifstream file1(\"drive/My Drive/Seq_Classification/labels.txt\");\n",
    "    if (file1.is_open()) {\n",
    "        std::string line;\n",
    "        while (std::getline(file1, line)) \n",
    "        {\n",
    "            // using printf() in all tests for consistency\n",
    "            vector<string> temp;\n",
    "            for(int i=0;i<line.length();i+=2)\n",
    "            {\n",
    "                string tag(1,line[i]);\n",
    "                temp.push_back(tag);\n",
    "            }\n",
    "            labels.push_back(temp);\n",
    "        }\n",
    "        file1.close();\n",
    "    }\n",
    "\n",
    "    // for(int i=0;i<pred.size();i++)\n",
    "    // {\n",
    "    //     for(int j=0;j<pred[i].size();j++)\n",
    "    //         cout<<pred[i][j];\n",
    "    //     cout<<endl;\n",
    "    // }\n",
    "    // for(int i=0;i<labels.size();i++)\n",
    "    // {\n",
    "    //     for(int j=0;j<labels[i].size();j++)\n",
    "    //         cout<<labels[i][j];\n",
    "    //     cout<<endl;\n",
    "    // }\n",
    "\n",
    "    Res result = testSequential(pred,labels);\n",
    "\n",
    "    cout<<result.vec[0][0]<<\" \"<<result.vec[0][1]<<endl;\n",
    "    cout<<result.vec[1][0]<<\" \"<<result.vec[1][1]<<endl;\n",
    "    cout<<result.vec[2][0]<<\" \"<<result.vec[2][1]<<endl;\n",
    "    return 0;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ELMO residual LSTM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
